function results = Kernel_regression( sitecode , ...
                                      load_stored_data , ...
                                      varargin )
% KERNEL_REGRESSION- main function for Kernel regressions
p = inputParser;
p.addRequired( 'sitecode', @(x) ( isintval(x) | isa( x, 'UNM_sites' )));
p.addRequired( 'load_stored_data', @islogical );
p.addParameter( 'surface_name', 'FC', ...
    @(x) strcmpi( x, 'FC' ) | strcmpi( x, 'GPP' ) | ...
    strcmpi(x ,'RE') | strcmpi( x , 'ET_mm_dayint' ) );
p.addParameter('growing_season', false);
p.addOptional( 'wateryear' , false)




p.parse( sitecode, load_stored_data, varargin{ : } );

sitecode = p.Results.sitecode;
load_stored_data = p.Results.load_stored_data;
contour_var = p.Results.surface_name;
use_wateryear = p.Results.wateryear;
growing_season = p.Results.growing_season;



%colormap_greens = flipud( cbrewer( 'seq', 'YlGn', 100 ) );
% colour(1,:)=[0.9 0.5 0.0];
% colour(2,:)=[0.6 0.2 0];
% colour(3,:)=[0.25 1.0 0.0];
% colour(4,:)=[0.0 0.5 0.0];
% colour(5,:)=[0.5 0.5 1.0];
% colour(6,:)=[0.0 0.0 0.6];

% ------------------------------
% Get growing season Julian Dates
% -------------------------------
config = parse_yaml_config(sitecode,'SiteVars');
start_growing_jday = config.start_growing_jday;
end_growing_jday = config.end_growing_jday;
   



%  firstday = repmat( 1, 1, n );
%  lastday = repmat( 365, 1, n );
%  fprintf( 'CONSIDERING DOY 1 TO 365!\n' );

% yax_min = [ 0.025, 0.025, 0.05, 0.05, 0.05, 0.05 ];
% yax_max = [ 0.15, 0.15, 0.225, 0.225, 0.22, 0.22 ];
% xax_min = [ -8, -8, -8, -8, -8, -8 ];
% xax_max = [ 28, 28, 24, 24, 19, 19 ];

if load_stored_data
    load( sprintf('data/KR_parsed_data_%s.mat' , char( sitecode ) ) );
else   
    % Parse Ameriflux Daily files
    data = get_kernel_regression_data( sitecode );
    % Save the site as a mat file
    save( sprintf('data/KR_parsed_data_%s.mat', char(sitecode) ), 'data' ) ;
end

%for  i = 1:length(sitelist)
    %sitecode = sitelist{i}; % Use this if you are indexing based on UNM_sites order
   % sitecode = i ; % Use this if indexing is based on the order of list as fed into the program (from main.m)
    % parsing takes a minutes -- option to load saved data
    
    % define some conversion factors
    mu2e=(1*60*30)./1000000; 
    mu2g=((1./1000000)*12)*60*30;
    
    % only consider data during growing season
    if growing_season
    growing_season = ( ( data.DOY >= start_growing_jday ) & ...
                       ( data.DOY <= end_growing_jday ) );
    data = data( find( growing_season ), : );
    end
    
    %---------------------
    % Remove NaN to ignore years of missing/non qced soil data
    % This applies specifically to MCon, which we need to QC prior to the
    % fire
    skip_rows = ( ~isfinite(data.SWC_SHALL) & ...
                   ~isfinite(data.SWC_MID) & ...
                   ~isfinite(data.SWC_DEEP));
    data(skip_rows,:) = [];
%     
%  Tims code separates NEE into day and nighttime values, but our files no    
%     % separate NEE into daytime, nighttime
%     data.NEE_day = data.FC .* mu2g;
%     data.NEE_day( ( data.HRMIN <= 530 ) | ( data.HRMIN >= 1830 ) ) = NaN;
%     data.NEE_night = data.FC .* mu2g;
%     data.NEE_night( ( data.HRMIN > 530 ) & ( data.HRMIN < 1830 ) ) = NaN;
    
    % replace -9999 with NaN
%     data_dbl = double( data );
%     data = replacedata( data, replace_badvals( data_dbl, ...
%                                                [-9999], ...
%                                                1e-6 ) );

    % give each day a unique integer index starting with 1 Jan 2007 = 1
%     day_idx = datenum( data.YEAR, 1, 0 ) + data.DOY - ...
%               datenum( 2007, 1, 0 );    
    %  day_idx = data.TIMESTAMP - datenum(2007,1,0);

    % aggregate the data by daily sum or daily mean, as appropriate for each
    % observation
%     vars_to_avg = { 'TA', 'SWC_shallow', 'SWC_deep_10_20', ...
%                     'SWC_deep_20_30', 'SWC_deep_30plus', 'PAR' };
%     vars_to_sum = { 'NEE_day', 'NEE_night', 'RE', 'GPP', 'PRECIP' };
% 
%     [ sum_day_idx, agg_sums ] = ...
%         consolidator( day_idx, ...
%                       double( data( :, vars_to_sum ) ), ...
%                       @nansum );
%     [ mean_day_idx, agg_means ] = ...
%         consolidator( day_idx, ...
%                       double( data( :, vars_to_avg ) ), ...
%                       @nanmean );
% 
%     % calculate timestamps for  aggregated data
%     agg_data = [ dataset( { agg_sums, vars_to_sum{ : } } ), ...
%                  dataset( { agg_means, vars_to_avg{ : } } ) ];
%     agg_dates = datenum( 2007, 1, 0 ) + mean_day_idx;
%     [ year, ~, ~, ~, ~, ~ ] = datevec( agg_dates );
%     agg_data.YEAR = year;
%     agg_data.DOY = agg_dates - datenum( year, 1, 0 );
%     
    % calculate climate space for this site
    
    [year,~,~]=datevec(data.TIMESTAMP);
%    day_idx = find( ~data.NIGHT );
%    night_idx = find( data.NIGHT );
    climspace_shallow = ...
        calculate_climate_space( sitecode,...
                                 data.TA, ...
                                 data.SWC_SHALL, ...
                                 year, ...
                                 6);
         
    climspace_mid = ...
        calculate_climate_space( sitecode, ...
                                 data.TA, ...
                                 data.SWC_MID, ...
                                 year, ...
                                 23);
    climspace_deep = ...
        calculate_climate_space( sitecode, ...
                                 data.TA, ...
                                 data.SWC_DEEP, ...
                                 year, ...
                                 60);

    % remove data from days with precipitation or days following days with
    % precipitation
    pcp_remove = find( data.PRECIP > 0 );
    pcp_remove( pcp_remove > size( data, 1 ) ) = [];
    data( pcp_remove , : ) = [];
            

    % Daily NEE
    
    fprintf( '%s shallow / 24 hr \n', char( UNM_sites( sitecode ) ) );
    shallow = ... 
        kernel_regression_wrapper( sitecode, ...
                                   data.TA, ...
                                   data.SWC_SHALL, ...
                                   data{:,contour_var}, ...
                                   sprintf('SWC 0-6 cm, %s',contour_var  ) );
    
    fprintf( '%s shallow /nighttime\n', char( UNM_sites( sitecode ) ) );
    shallow_night = ... 
        kernel_regression_wrapper( sitecode, ...
                                   data.TA, ...
                                   data.SWC_SHALL_NIGHT, ...
                                   data{:,contour_var}, ...
                                   sprintf('SWC 0-6 cm (night), %s ', contour_var ) );
                    
    fprintf( '%s shallow /daytime\n', char( UNM_sites( sitecode ) ) );
    shallow_day = ... 
        kernel_regression_wrapper( sitecode, ...
                                   data.TA, ...
                                   data.SWC_SHALL_DAY, ...
                                   data{:,contour_var}, ...
                                   sprintf('SWC 0-6 cm (day), %s ', contour_var ) );

    fprintf( '%s mid /daily\n', char( UNM_sites( sitecode ) ) );    
    mid = ... 
        kernel_regression_wrapper( sitecode, ...
                                   data.TA, ...
                                   data.SWC_MID, ...
                                   data{:,contour_var}, ...
                                   sprintf('SWC 6-23 cm, %s ', contour_var ) );
    
    fprintf( '%s deep / daily \n', char( UNM_sites( sitecode ) ) );
    deep = ... 
        kernel_regression_wrapper( sitecode, ...
                                   data.TA, ...
                                   data.SWC_DEEP, ...
                                   data{:,contour_var}, ...
                                   sprintf('SWC 23+ cm,  %s ', contour_var ) );
                                  
       results = ...
        site_T_SWC_flux_data( UNM_sites( sitecode ), ...
                              shallow, ...
                              shallow_night, ...
                              shallow_day,...
                              mid, ...
                              deep, ...
                              climspace_shallow,...
                              climspace_mid, ...
                              climspace_deep, ...
                              sprintf('%s surfaces', ...
                                      char( UNM_sites( sitecode ) ) ) ); 
%end  % site loop 

% if not( load_stored_data )
%     save( 'kernel_regression_parsed_data.mat', 'all_data' );
% end
% save( 'kernel_regression_aggregated_data.mat', 'all_agg_data' );
% 


%==================================================
function KR_sfc = kernel_regression_wrapper( sitecode, T, SWC, NEE, note_str )
% KERNEL_REGRESSION_WRAPPER - perform kernel regression to calculate
%   NEE = f( T, SWC ).  Store output surface in T_SWC_flux_sfc object.

% whether to do the kernel regression or return the plain histogram

kr_switch = struct( 'do_KR', true, 'hist_only', false );

[ flux_sfc, n_count, swc_bin_ctrs, T_bin_ctrs ] = ...
    calculate_SWC_T_NEE_kernel_regression( T, ...
                                           SWC, ...
                                           NEE, ...
                                           kr_switch.do_KR );

KR_sfc = T_SWC_flux_sfc( UNM_sites( sitecode ), ...
                         swc_bin_ctrs, ...
                         T_bin_ctrs, ...
                         flux_sfc, ...
                         n_count, ...
                         note_str );